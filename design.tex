\chapter{Application Design}
\label{cha:design}

After defining the mechanisms which will be implemented, in a next step, the general application flow will be described, as well as offering insight into the user experience design of all parts of the application. What is important to note is that the design discussed here is just the default layout and can easily be changed and adapted by the presenter. All features identified in chapter \ref{cha:mechanisms} can be turned on or off, in the following it is assumed that all of them are enabled.

\section{Application Flow}
The flow and usage of the application is separated into two parts: the creation and authoring of the presentation and giving the presentation. As the technical details of how slide decks are composed are covered in chapter \ref{cha:implementation}, this chapter focuses on the user interface and interaction design of the software from the speaker's and the audience's perspective, during the presentation.

The typical setup of an unveil presentation is as follows: We assume a presenter called Amy, who has already prepared her presentation and a listener called Greg who wants to follow the presentation from his smartphone.
The slides are generally served from a server. This can either be a publicly accessible server or, if all participants are in the same network, locally from Amy's computer. We assume Amy is serving the slides from her laptop, which is connected to a projector.
At the beginning of the presentation, Greg and all other listeners navigate their personal devices' browsers to the set up address (usually a combination of IP address and port). To make this step easier, Amy has put a QR code pointing to the address on the first slide and sent out an e-mail with the link to all participants before the start of the presentation.

The software supports three different modes out of the box: listener, speaker and projector mode. Depending on the mode, a certain set of features is activated, allowing Amy to have a different interface and more controls than Greg. Modes are activated via query parameters in the url: Amy navigates her laptop's browser to the url of the presentation and adds the query parameter \texttt{mode=projector}. On her smartphone, which she wants to use for remote controlling the presentation, the mode is set to \texttt{speaker}. If no query parameter is given, the application defaults to the listener mode, so Greg simply types in the address or follows the link in the url or QR code. Unveil generally offers a two-dimensional slide space, consisting of master slides (left to right) and subslides (top to bottom). Devices in speaker mode (in this example Amy's smartphone) can remote-control the presentation and navigate through said slides. All other devices (the laptop in projector mode and Greg's phone) are synchronised with the state of Amy's phone and automatically follow along in real-time.

% Base CSS: responsive, if content is too big, everything is uniformly scaled.

% Application Flow, Modes, How does the application work in general?
% Design aspects, sketches, wireframes, thoughts and Ã¼berlegungen behind design details

\section{General Interface}
The general requirement for the interface of the application is to work in all three modes, on any device, from mobile phones to desktops and projectors. When in projector mode, only the content of the current slide, as well as listener reactions are shown (see figure \ref{fig:design-interface-projector}). In listener mode, the interface is a lot richer and additionally features buttons for sharing media, links and asking questions, as well as six different reactions (see figure \ref{fig:design-interface-listener}), which will be discussed in more detail in section \ref{sec:design-reactions}. It also offers small arrow buttons, to navigate between slides. The speaker interface is the most intricate: Besides showing the current slide, we believe it should also include a preview of the upcoming slides in $x$ (master slide) and $y$ (subslide) direction, as well as speaker notes. Additionally to this interface, already familiar from PowerPoint or similar presentation software, buttons to mute incoming requests (media, link and questions) and to create new polls are provided (see figure \ref{fig:design-interface-presenter}). Since we expect presenters to switch between devices more often than listeners for more typing-intense tasks such as creating new polls, the mobile interface is as similar as possible to the desktop one and only re-arranges the displayed information to fit on smaller screens. The main difference between the mobile and desktop version of the listener interface is the design of the reactions: While desktop computers and tablets offer ample space for the placement of all six emoji, these are hidden behind a button in the mobile interface and only slide up upon a tap on said button.

\begin{figure}\centering\includegraphics[width=.65\textwidth]{wireframes/projector-interface}\caption{Wireframe of slide in projector mode, as seen on a projector. No visual controls are shown, only the current slide and listener reactions are displayed. The presentation progresses through the presenter mode's remote controlling feature.}\label{fig:design-interface-projector}\end{figure}

\begin{figure}\centering\includegraphics[width=.831\textwidth]{wireframes/listener-interface}\caption{Wireframes of general interface in listener mode for mobile phones and desktops. Both offer buttons to share media, links and questions with the presenter, arrow buttons to navigate through the presentation and a possibility to react to the current slide. On mobile this feature is revealed with a tap on the \emph{reaction} button, to not cluster the interface.}\label{fig:design-interface-listener}\end{figure}

\begin{figure}\centering\includegraphics[width=.65\textwidth]{wireframes/speaker-interface}\caption{Wireframes of general interface in speaker mode for mobile phones and desktops. The interface consists of a preview of the current slide, the next main slide (\emph{right}) and the next subslide (\emph{down}), as well as showing presenter notes. It also offers buttons to toggle muting of incoming requests and creation of new polls.}\label{fig:design-interface-presenter}\end{figure}

\begin{figure}\centering\includegraphics[width=.65\textwidth]{wireframes/modal-interface}\caption{Wireframes of modal interface in speaker mode for mobile phones and desktops. The shown modal allows the presenter to add a listener-submitted video as a new main or subslide or dismiss the request. It pops up as soon as a listener wants to share content with the slide.}\label{fig:design-interface-modal}\end{figure}

\section{General Interaction Principles}
As far as the interaction design of the application is concerned, the main requirement technically is for all state changes to take immediate effect or in other words, for the software to work in real-time. This is true for interactions with the server as well as all internal state changes within the application. All transitions and animations last $200$ms, a value which is both usable on mobile phones and desktops and, according to Google's Material Design Guide \cite{GoogleMaterialDesignGuide} ``fast enough that it doesn't cause waiting, but slow enough that the transition can be understood''. An easing curve with low outgoing and high incoming velocity is used.

The general aim for the interaction design of the application is to be as easy and intuitive to use as possible on any device, for both presenters and listeners. Especially the speaker's view has a lot of information to display and many ways of interacting with the interface. From the speaker's point of view, the main reason for negative presentation experiences stems from technical difficulties and problems \cite{Wacker:PresenterExperience}; we therefore decided to design a presenter interface similar to the one already known from PowerPoint, Keynote, Google Slides or reveal.js (see figure \ref{fig:design-interface-presenter}) and employ familiar visual metaphors and interaction mechanisms such as buttons and modals (see \ref{gifig:design-interface-modal}).

Another important consideration when it comes to mobile and desktop environments is the question of supported inputs. While mouse and keys are a natural and intuitive way of navigating through desktop applications, swiping gestures are faster, more accurate \cite{Lai:SingleHandedThumbInteraction} and require less time looking at the screen on mobile devices \cite{Negulescu:TapSwipeMove}, making them the ideal candidate for the remote-controlling feature. For this reason, additionally to providing visual arrow-buttons for navigation, arrow-keys and swipe gestures are also supported. The interaction with buttons is controlled by mouse clicks or taps, respectively and common visual metaphors are used to symbolises their state (pressed, hovered, disabled), as shown in figure \ref{fig:design-interface-button}.

Now that the general interaction principles are covered, a more detailed look is taken at the most interesting parts of the implemented features.

\begin{figure}\centering\begin{tabular}{ccc}
\includegraphics[width=.2\textwidth]{button-state-normal} &
\includegraphics[width=.2\textwidth]{button-state-hover} &
\includegraphics[width=.2\textwidth]{button-state-disabled} \\
(a) & (b) & (c)
\end{tabular}\caption{Button states, (a) normal, (b) hovered or active and (c) disabled.}\label{fig:design-interface-button}\end{figure}

\section{Reactions}
\label{sec:design-reactions}
% Emojis
% Find more studies about this! think: facebook, the conference Paulo went to etc. (maybe add photo of audience showing emoji faces!)
% It is therefore important to provide more detailed feedback. Following the evaluation in \cite{Teevan:MobileFeedbackDuringPresentation}, the mechanism proposed in this thesis offers three emotions (approval, laughter, boredom) and three request types (louder, speed up, slow down).
Although binary digital reactions to a presentation are not an entirely new idea \cite{Teevan:MobileFeedbackDuringPresentation}, versatile feedback that goes beyond positive and negative, to our knowledge, has not yet been explored. From the evaluation in \cite{Teevan:MobileFeedbackDuringPresentation} and \cite{Isaacs:InteractivePresentationsDistributedAudience} and from observing presentations and meetings, a pool of possible reactions has been narrowed down to six --  three emotions (approval, laughter, boredom) and three request types (louder, speed up, slow down) (see figure \ref{fig:design-reactions}). The reason behind the missing disapproval is on one hand that test subjects in \cite{Teevan:MobileFeedbackDuringPresentation} felt less comfortable giving negative feedback and the button was used less than the positive one and included reactions such as \emph{boredom} or \emph{speed up} and \emph{slow down}, on the other side we hope this will encourage more elaborate feedback of disagreement using the content sharing functionality instead.

Since the presentation of feedback in \cite{Teevan:MobileFeedbackDuringPresentation} was perceived as a distraction from the presentation, the feedback mechanism proposed in the present work is either only shown to the presenter or displayed in the right corner of the projector, with a small badge symbolising how many people have sent this feedback for the current slide (see figure \ref{fig:design-reactions-details} (a)).

Another challenge with displaying non-binary feedback was to find an intuitive and familiar visualisation which would not take up too much space on smaller screens. Since the introduction of emoji on Apple's keyboard in 2011 and on Android's one in 2013, emoji have become a ubiquitous, language-independent means of communicating \cite{Instagramm:Emoji, Cappallo:EmojiVideoSearch}. Instagram has found that almost half of its comments and captions nowadays include emoji. With Google \cite{Google:Emoji} and Bing \cite{Bing:Emoji} adding support for emoji-search and companies like Facebook \cite{Facebook:Reactions} and GitHub \cite{Github:Reactions} offering emoji-based reaction systems, it is safe to assume the majority of digital natives is familiar with the concept and meaning of emojis. Although it would be possible to include a complete emoji-keyboard we feel it is easier for less technology-oriented users to offer only a sub-set including a short description of each reaction (see figure \ref{fig:design-reactions}). However, this sub-set can easily be extended or overwritten by the presenter.

Another detail worth mentioning is the hover-effect of the emoji, which is of special importance on desktops (see figure \ref{fig:design-reactions-details} (b)).

\begin{figure}\centering
\includegraphics[width=.65\textwidth]{reactions}
\caption{All six possible reactions and their emoji (from left): \emph{approval}, \emph{laughter}, \emph{boredom}, \emph{louder}, \emph{speed up} and \emph{slow down}. The \emph{speed up} emoji is in hover-state.}\label{fig:design-reactions}\end{figure}

\begin{figure}\centering\begin{tabular}{ccc}
\includegraphics[width=.2\textwidth]{reactions-badge} &
\includegraphics[width=.2\textwidth]{reactions-hover} \\
(a) & (b)
\end{tabular}\caption{Details of visualisation of reactions (a) with number of reactions as found in the presenter view and optionally the projector and (b) with hover status as found on listener interface.}\label{fig:design-reactions-details}\end{figure}

% could theoretically also use all emojis, for even more interesting feedback and freedom!


\section{Polls}
% Polls: Describe why freeze navigation while voting and only allow voting when started by presenter
% Growing balken!
% Wie kann eine neue erstellt werden?

\section{Content Sharing}
% Sharing: show that it's possible to take photos on the phone directly!
% Explain muting
% Maybe use greg and amy again to show how greg copies a youtube link over or something
